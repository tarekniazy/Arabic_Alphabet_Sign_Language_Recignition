{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from SkinDetection import *\n",
    "from HandDetection import *\n",
    "from Utilities import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static images model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "directories = [ 'images/AL/frame',          # 0\n",
    "                'images/Alef/frame',        # 1\n",
    "                'images/BB/frame',          # 2\n",
    "                'images/dhad/frame',        # 3\n",
    "                'images/four/frame',        # 4\n",
    "                'images/ghain/frame',       # 5\n",
    "                'images/jeem/frame',        # 6\n",
    "                'images/LA/frame',          # 7\n",
    "                'images/lam/frame',         # 8\n",
    "                'images/O/frame',           # 9\n",
    "                'images/okay/frame',        # 10\n",
    "                'images/openpalm/frame',    # 11\n",
    "                'images/peace/frame',       # 12\n",
    "                'images/three/frame',       # 13\n",
    "                'images/ya/frame',          # 14\n",
    "                'images/starting/frame'     # 15\n",
    "            ]\n",
    "labels = list(range(0, len(directories)))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read Dataset\n",
    "2. Apply Preproccessing\n",
    "3. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/AL/frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:114: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  check = np.bitwise_and(red_dash/green_dash > 1.185, np.bitwise_and(cb > 77, np.bitwise_and(cb < 127,np.bitwise_and(cr > 133, np.bitwise_and(cb < 173 , np.bitwise_and(saturation >= 0.2 , np.bitwise_and(saturation<= 0.6 , np.bitwise_and(hue >=0 , np.bitwise_and( hue <= 25 , np.bitwise_or(hue >= 335 , hue <= 360))))))))))\n",
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:69: RuntimeWarning: invalid value encountered in true_divide\n",
      "  red_dash = red/(red+green+blue)\n",
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:70: RuntimeWarning: invalid value encountered in true_divide\n",
      "  green_dash = green/(red+green+blue)\n",
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:71: RuntimeWarning: invalid value encountered in true_divide\n",
      "  blue_dash = blue/(red+green+blue)\n",
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  check = np.bitwise_and(red_dash/green_dash > 1.185, np.bitwise_and(cb > 77, np.bitwise_and(cb < 127,np.bitwise_and(cr > 133, np.bitwise_and(cb < 173 , np.bitwise_and(saturation >= 0.2 , np.bitwise_and(saturation<= 0.6 , np.bitwise_and(hue >=0 , np.bitwise_and( hue <= 25 , np.bitwise_or(hue >= 335 , hue <= 360))))))))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/Alef/frame\n",
      "images/BB/frame\n",
      "images/dhad/frame\n",
      "images/four/frame\n",
      "images/ghain/frame\n",
      "images/jeem/frame\n",
      "images/LA/frame\n",
      "images/lam/frame\n",
      "images/O/frame\n",
      "images/okay/frame\n",
      "images/openpalm/frame\n",
      "images/peace/frame\n",
      "images/three/frame\n",
      "images/ya/frame\n",
      "images/starting/frame\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame(columns=['H[0]', 'H[1]','H[2]','H[3]','H[4]','H[5]','H[6]' ,'Label'])\n",
    "\n",
    "dataset = []\n",
    "for index in range(0,len(directories)):\n",
    "    print(directories[index])\n",
    "    for x in range(100,400):\n",
    "\n",
    "        filename = directories[index] + str(x) + '.jpg'\n",
    "        try:\n",
    "            image = io.imread(filename)\n",
    "            cv2_image = cv2.imread(filename)\n",
    "        except:\n",
    "            continue\n",
    "        one = SkinDetection_InRange(cv2_image)\n",
    "        two = SkinDetection_Multiscale(image)\n",
    "        \n",
    "\n",
    "        final = cv2.bitwise_and(one,two)\n",
    "\n",
    "        _, hand = HandDetection(final)\n",
    "\n",
    "        # cv2.imwrite(\"processed/frame\" + str(x) + '.jpg', hand)\n",
    "\n",
    "        huMoments = seven_hu_moments(hand)\n",
    "        huMoments = abs(huMoments)\n",
    "        huMoments = np.append(huMoments ,np.array(labels[index]))\n",
    "        dataset.append(huMoments)\n",
    "# #         df = df.append(pd.DataFrame(huMoments.reshape(1,-1), columns=list(df)), ignore_index=True)\n",
    "\n",
    "# # print(df)\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier - VotingClassifier (SVM+KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3607, 8)\n",
      "SVM 0.8761429758935994\n",
      "KNN 0.7913549459684123\n",
      "Combined Voting 0.8711554447215295\n"
     ]
    }
   ],
   "source": [
    "data_array = np.array(dataset)\n",
    "print(data_array.shape)\n",
    "y = data_array[:, -1]\n",
    "x = data_array[:, :-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 1/3, random_state=42)\n",
    "\n",
    "clf = svm.SVC(probability=True ,kernel = 'rbf', gamma=1/3, C=1500)\n",
    "clf.fit(X_train, y_train)\n",
    "print('SVM' , clf.score(X_test, y_test))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "print('KNN' , knn.score(X_test, y_test))\n",
    "\n",
    "static_combine = VotingClassifier(estimators=[('SVM',clf) ,('KNN',knn)],voting='soft',weights = [2,1])\n",
    "static_combine.fit(X_train, y_train)\n",
    "print('Combined Voting' ,static_combine.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the models for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(static_combine, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = pickle.load(open('finalized_model.sav', 'rb'))\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    _,frame = cap.read()\n",
    "    \n",
    "    cv2.imwrite('Khaled/frame'+str(count) +'.jpg', frame)\n",
    "    image = io.imread('Khaled/frame'+str(count) +'.jpg')\n",
    "    # count += 1\n",
    "\n",
    "    one = SkinDetection_InRange(frame)\n",
    "    two = SkinDetection_Multiscale(image)\n",
    "    final = cv2.bitwise_and(one,two)\n",
    "    binary, hand = HandDetection(final)\n",
    "\n",
    "    huMoments = seven_hu_moments(hand)\n",
    "    huMoments = abs(huMoments)\n",
    "    testing = np.array(huMoments)\n",
    "\n",
    "    label = int(static_combine.predict(testing.T))\n",
    "    print(directories[label])\n",
    "    # if (label == \n",
    "    cv2.imshow(\"Main\",frame)\n",
    "    # cv2.imshow(\"IO\",image)\n",
    "    # cv2.imshow(\"One\",one)\n",
    "    # cv2.imshow(\"Two\",two)\n",
    "    cv2.imshow(\"Final\",binary)\n",
    "    cv2.imshow(\"Hand\",hand)\n",
    "    \n",
    "    if cv2.waitKey(1)& 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#Releasing the camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:114: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  check = np.bitwise_and(red_dash/green_dash > 1.185, np.bitwise_and(cb > 77, np.bitwise_and(cb < 127,np.bitwise_and(cr > 133, np.bitwise_and(cb < 173 , np.bitwise_and(saturation >= 0.2 , np.bitwise_and(saturation<= 0.6 , np.bitwise_and(hue >=0 , np.bitwise_and( hue <= 25 , np.bitwise_or(hue >= 335 , hue <= 360))))))))))\n",
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  check = np.bitwise_and(red_dash/green_dash > 1.185, np.bitwise_and(cb > 77, np.bitwise_and(cb < 127,np.bitwise_and(cr > 133, np.bitwise_and(cb < 173 , np.bitwise_and(saturation >= 0.2 , np.bitwise_and(saturation<= 0.6 , np.bitwise_and(hue >=0 , np.bitwise_and( hue <= 25 , np.bitwise_or(hue >= 335 , hue <= 360))))))))))\n",
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:69: RuntimeWarning: invalid value encountered in true_divide\n",
      "  red_dash = red/(red+green+blue)\n",
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:70: RuntimeWarning: invalid value encountered in true_divide\n",
      "  green_dash = green/(red+green+blue)\n",
      "e:\\kolya\\Sana 4\\Image Processing\\Cleaner_Version\\SkinDetection.py:71: RuntimeWarning: invalid value encountered in true_divide\n",
      "  blue_dash = blue/(red+green+blue)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900,)\n"
     ]
    }
   ],
   "source": [
    "dir=[[directories[0],directories[2]],[directories[8],directories[6]],[directories[3],directories[14]]]\n",
    "\n",
    "seq_dataset=[]\n",
    "\n",
    "seq_based_labels=[]\n",
    "\n",
    "for i in range(len(dir)):\n",
    "\n",
    "    for j in range(100,400):\n",
    "        one_sequence = np.zeros((7*len(dir[0])))\n",
    "        start_slicing=0\n",
    "        end_slicing=7\n",
    "\n",
    "        for fr in dir[i]:\n",
    "\n",
    "            filename = fr + str(j) + '.jpg'\n",
    "\n",
    "            try:\n",
    "                image = io.imread(filename)\n",
    "                cv2_image = cv2.imread(filename)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            one = SkinDetection_InRange(cv2_image)\n",
    "            two = SkinDetection_Multiscale(image)\n",
    "\n",
    "            final = cv2.bitwise_and(one,two)\n",
    "\n",
    "            _, hand = HandDetection(final)\n",
    "\n",
    "            huMoments = seven_hu_moments(hand)\n",
    "            huMoments = abs(huMoments)\n",
    "\n",
    "            one_sequence[start_slicing:end_slicing]=huMoments.T\n",
    "\n",
    "        \n",
    "        seq_dataset.append(one_sequence)\n",
    "\n",
    "        seq_based_labels.append(i)\n",
    "            \n",
    "            # start_slicing+=end_slicing\n",
    "            # end_slicing+=end_slicing\n",
    "           \n",
    "\n",
    "        \n",
    "        \n",
    "print(np.array(seq_based_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 14)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(seq_dataset).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC(C=1000))])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq_train, X_seq_test, y_seq_train, y_seq_test = train_test_split(seq_dataset, seq_based_labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=111)\n",
    "\n",
    "clf_seq = make_pipeline(StandardScaler(), SVC(gamma='scale', C=1000))\n",
    "\n",
    "clf_seq.fit(X_seq_train,y_seq_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3dc724101d1844b82d7408b05ff3e3c012f86a112e03100039ce4c20641155e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('pattern': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
